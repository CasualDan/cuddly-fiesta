{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b071c638",
   "metadata": {},
   "source": [
    "---\n",
    "Supplement to Master Thesis Presented to the Department of Economics at the Rheinische Friedrich-Wilhelms-Universit√§t Bonn | by\n",
    "[Muhammad Danial Syed](https://github.com/MDanialSyed) <br>\n",
    "\n",
    "---\n",
    "# \"CAUSAL INFERENCE USING RANDOM FORESTS AND LASSO\" - Code\n",
    "#### by Muhammad Danial Syed\n",
    "\n",
    "This notebook contains replication codes for my thesis based on the Generalized Random Forest method introduced in [Generalized Random Forests](https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-2/Generalized-random-forests/10.1214/18-AOS1709.full) (Athey et al., 2019)\n",
    "\n",
    "The following packages are used to implement the method and for comparison purposes with [Double Machine Learning](https://academic.oup.com/ectj/article/21/1/C1/5056401) and [Double Selection](https://academic.oup.com/restud/article-abstract/81/2/608/1523757?redirectedFrom=fulltext)\n",
    "- [GRF](https://grf-labs.github.io/grf/index.html)\n",
    "- [DoubleML](https://docs.doubleml.org/stable/index.html)\n",
    "- [MLR3 Learners](https://mlr3learners.mlr-org.com)\n",
    "- [hdm](https://cran.r-project.org/web/packages/hdm/index.html)\n",
    "\n",
    "#### Source material\n",
    "The project uses the above `GRF` package for its main computations and also relies on certain modifications of the [source code](https://github.com/grf-labs/grf/blob/master/r-package/grf/R/dgps.R) to alter the data generating process.\n",
    "\n",
    "#### Overview\n",
    "\n",
    "Part I: A multi-part simulation study that complements the theoretical portion of my thesis and critically examines some of the main components of GRF:\n",
    "1. Flexible estimation of nonparametric functions.\n",
    "2. Causal forest with and without Honesty.\n",
    "3. Causal forest compared with Double Machine Learning and Post Double-Selection.\n",
    "4. Predicting Treatment Heterogeneity with causal forests.\n",
    "\n",
    "Part II: A two-pronged robustness check of the empirical applicability of GRF.\n",
    "1. *The Impacts of Microcredit: Evidence from Bosnia and Herzegovina* (Augsburg et al., 2015)\n",
    "2. *Effect of 401(k) eligibility and participation on net financial assets*\n",
    "\n",
    "#### Table of Content\n",
    "\n",
    "1. [Flexible estimation of nonparametric functions - OLS and GRF Fit (Figure 1)](#1)  <br>\n",
    "    1.1. [Data Generating Process 1](#2) <br>\n",
    "2. [Estimating Average Treatment Effects](#2) <br>\n",
    "    2.1. [Data Generating Process 2](#2) <br>\n",
    "    2.2. [Simulation - Honest and Dishonest Causal Forest for ATEs](#2) <br>\n",
    "    2.3. [Causal Forests, Double Machine Learning, and Post Double Selection LASSO](#2) <br>\n",
    "3. [Predicting HTEs](#8) <br>\n",
    "    3.1. [Data Generating Process 3](#9) <br>\n",
    "    3.2. [Simulation Experiments: Honest and Dishonest Forests for HTEs](#11) <br>\n",
    "4. [Empirical Application: *The Impacts of Microcredit: Evidence from Bosnia and Herzegovina*](#15) <br>\n",
    "5. [Empirical Application: *Effect of 401(k) eligibility and participation on net financial assets*](#16) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1af9b",
   "metadata": {},
   "source": [
    "---\n",
    "## Part I: Simulation Studies\n",
    "---\n",
    "\n",
    "### Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf37ccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T18:11:54.054709Z",
     "start_time": "2022-08-15T18:11:51.659Z"
    }
   },
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "\n",
    "suppressMessages(library(grf))\n",
    "suppressMessages(library(hdm))\n",
    "suppressMessages(library(doMC))\n",
    "suppressMessages(library(mlr3))\n",
    "suppressMessages(library(haven))\n",
    "suppressMessages(library(ranger))\n",
    "suppressMessages(library(glmnet))\n",
    "suppressMessages(library(xtable))\n",
    "suppressMessages(library(ggplot2))\n",
    "suppressMessages(library(mvtnorm))\n",
    "suppressMessages(library(reshape2)) \n",
    "suppressMessages(library(parallel))\n",
    "suppressMessages(library(DoubleML))\n",
    "suppressMessages(library(data.table))\n",
    "suppressMessages(library(mlr3learners))\n",
    "suppressMessages(library(clusterGeneration))\n",
    "lgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n",
    "\n",
    "numCores <- detectCores()\n",
    "registerDoMC(cores = numCores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420eb282",
   "metadata": {},
   "source": [
    "___\n",
    "### 1 - Flexible estimation of nonparametric functions - OLS and GRF Fit (Figure 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16394af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T18:11:57.461796Z",
     "start_time": "2022-08-15T18:11:55.034Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "\n",
    "#Generate data from DGP 1\n",
    "X1 <- as.matrix(sort(rnorm(120,40,20)))\n",
    "Y1 <- as.matrix(rnorm(120,90 + exp(0.06*X1), 1))\n",
    "\n",
    "X0 <- as.matrix(sort(rnorm(120,20,20)))\n",
    "Y0 <- as.matrix(rnorm(120,72+3*sqrt(abs(X0)),1))\n",
    "\n",
    "# Data for True Response Curve\n",
    "X0_response <- sort(rnorm(120000,20,10))\n",
    "X1_response <- sort(rnorm(120000,40,10))\n",
    "\n",
    "X.test <- matrix(seq(0, 60, length.out = 120))\n",
    "\n",
    "# Train Regression Forest\n",
    "forest.treat <- regression_forest(X1, Y1)\n",
    "Y1.hat <- predict(forest.treat,X.test)$predictions\n",
    "\n",
    "forest.untreat <- regression_forest(X0, Y0)\n",
    "Y0.hat <- predict(forest.untreat,X.test)$predictions\n",
    "\n",
    "# OLS Plot\n",
    "plot(X0,Y0,xlim = c(2,60),ylim = c(75,130),pch = 5,xlab='X',ylab='Y',cex=1.2,cex.axis=1.5,cex.lab=1.5)\n",
    "points(X1,Y1,xlim = c(0,60),ylim = c(75,130), cex=1.2)\n",
    "lines(X0_response,72+3*sqrt(abs(X0_response)), col = 1, lwd = 1)\n",
    "lines(X1_response,90 + exp(0.06*X1_response), col = 1, lwd = 1)\n",
    "abline(lm(Y1 ~ X1), col = 4, lwd = 3)\n",
    "abline(lm(Y0 ~ X0), col = 3, lwd = 3)\n",
    "\n",
    "# GRF Plot\n",
    "plot(X0,Y0,xlim = c(2,60),ylim = c(75,130),pch = 5,xlab='X',ylab='Y',cex=1.2,cex.axis=1.5,cex.lab=1.5)\n",
    "points(X1,Y1,xlim = c(0,60),ylim = c(75,130), cex=1.2)\n",
    "lines(X0_response,72+3*sqrt(abs(X0_response)), col = 1, lwd = 1)\n",
    "lines(X1_response,90 + exp(0.06*X1_response), col = 1, lwd = 1)\n",
    "lines(X.test, Y1.hat, col =2, lwd = 3,lty=77)\n",
    "lines(X.test, Y0.hat, col =2, lwd = 3,lty=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca54223",
   "metadata": {},
   "source": [
    "___\n",
    "### 2 - Estimating Average Treatment Effects\n",
    "\n",
    "### 2.1. Data Generating Process 2\n",
    "- Adapted from GRF source code.\n",
    "- Modified to include constant treatment effect for select DGPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f3640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T05:01:30.310945Z",
     "start_time": "2022-08-15T05:01:30.288Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_DGP <- function(n, p, sigma.m = 1, sigma.tau = 0.1, sigma.noise = 1,\n",
    "                                 dgp = c(\"aw1\",\"nw1\",\"nw2\",\"nw3\")) {\n",
    "\n",
    "  # Create data\n",
    "    if (dgp == \"aw1\") {\n",
    "    X <- matrix(runif(n * p, min = 0, max = 1), n, p)\n",
    "    tau <- rep(1, n)  # Treatment effect is one\n",
    "    e <- (1 / 4)  * (exp(X[,3]) /(1 + exp(X[,3])))  # Confounding\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- 2 * X[, 1] - 1 + e * tau\n",
    "    V <- 1\n",
    "  } else if (dgp == \"nw1\") {\n",
    "    # Difficult nuisance components, easy treatment effect function.\n",
    "    X <- matrix(runif(n * p), n, p)\n",
    "    tau <- rep(1, n)\n",
    "    eta <- 0.1\n",
    "    e <- pmax(eta, pmin(sin(pi * X[, 1] * X[, 2]), 1 - eta))\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- sin(pi * X[, 1] * X[, 2]) + 2 * (X[, 3] - 0.5)^2 + X[, 4] + 0.5 * X[, 5] + e * tau\n",
    "    V <- 1\n",
    "  } else if (dgp == \"nw2\") {\n",
    "    # Randomized trial\n",
    "    X <- matrix(rnorm(n * p), n, p)\n",
    "    tau <- rep(1, n)\n",
    "    e <- rep(0.5, n)\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- pmax(0, X[, 1] + X[, 2], X[, 3]) + pmax(0, X[, 4] + X[, 5]) + e * tau\n",
    "    V <- 1\n",
    "  } else if (dgp == \"nw3\") {\n",
    "    # Strong confounding\n",
    "    X <- matrix(rnorm(n * p), n, p)\n",
    "    tau <- rep(1, n)\n",
    "    e <- 1 / (1 + exp(X[, 2] + X[, 3]))\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- 2 * log(1 + exp(X[, 1] + X[, 2] + X[, 3])) + e * tau\n",
    "    V <- 1\n",
    "  } \n",
    "\n",
    "  # Scale and return data\n",
    "  if (!is.na(sd(m)) & !(sd(m) == 0)) {\n",
    "    m <- m / sd(m) * sigma.m\n",
    "  }\n",
    "  if (!is.na(sd(tau)) & !(sd(tau) == 0)) {\n",
    "    tau <- tau / sd(tau) * sigma.tau\n",
    "  }\n",
    "  V <- V / mean(V) * sigma.noise^2\n",
    "  Y <- m + (W - e) * tau + sqrt(V) * rnorm(n)\n",
    "    \n",
    "    colnames(X) <- paste0(\"X\", 1:p)\n",
    "    YY <- as.data.frame(Y)\n",
    "    WW <- as.data.frame(W)\n",
    "    colnames(YY) <- \"Y\"\n",
    "    colnames(WW) <- \"W\"\n",
    "    data_dml = data.frame(X, YY, WW)\n",
    "\n",
    "  out <- list(X = X, Y = Y, W = W, tau = tau, m = m, e = e, dgp = dgp, dmldat = data_dml)\n",
    "\n",
    "  out\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e38760",
   "metadata": {},
   "source": [
    "### 2.1. Simulation - Honest and Dishonest Causal Forest for ATEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b22cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-07T23:53:31.192533Z",
     "start_time": "2022-08-07T18:23:37.733Z"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(123)     # random seed for replicability of results \n",
    "mse.reps <- 2500  # number of repetitions: set to 2500\n",
    "n <- 200          # number of observations\n",
    "p <- 30           # number of covariates\n",
    "tau <- 1          # true treatment effect is constant in all setups\n",
    "\n",
    "# DGPs with different levels of confounding \n",
    "dgp <- c(\"nw2\",\"aw1\",\"nw1\",\"nw3\")\n",
    "grid <- expand.grid(n = n, p = p, dgp = dgp, stringsAsFactors = FALSE)\n",
    "var_matrix <- matrix(NA, ncol = length(n)*length(p), nrow = mse.reps)\n",
    "\n",
    "# Function to apply GRF on DGPs and output estimates of tau\n",
    "out <- lapply(1:nrow(grid), function(i) {\n",
    "  n <- grid$n[i]\n",
    "  p <- grid$p[i]\n",
    "  dgp <- grid$dgp[i]\n",
    "  tau.hat <- replicate(mse.reps, {\n",
    "    data <- generate_DGP(n = n, p = p, dgp = dgp, sigma.tau = 1)\n",
    "    data.test <- generate_DGP(n = 1000, p = p, dgp = dgp, sigma.tau = 1)\n",
    "    cf_honest      <- causal_forest(data$X, data$Y, data$W, honesty = TRUE)    # honest forest\n",
    "    cf_not_honest  <- causal_forest(data$X, data$Y, data$W, honesty = FALSE)\n",
    "    tau_honest     <- average_treatment_effect(cf_honest, target.sample = \"all\",  method = \"TMLE\")[1]\n",
    "    tau_not_honest <- average_treatment_effect(cf_not_honest, target.sample = \"all\",  method = \"TMLE\")[1]\n",
    "    tau_estims <- cbind(tau_honest,tau_not_honest)\n",
    "\n",
    "  })\n",
    "\n",
    "  data.frame(dgp = dgp, p = p, n = n, C.GRF = tau.hat)\n",
    "})\n",
    "\n",
    "# Dataframe containing estimates of tau across all simulations\n",
    "tau_table <- do.call(rbind, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdae55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-07T23:55:26.458520Z",
     "start_time": "2022-08-07T23:55:26.375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate collective results into separate matrices\n",
    "mat1 <- as.matrix(tau_table[,4:ncol(tau_table)])\n",
    "colnames(mat1) <- NULL\n",
    "rownames(mat1) <- NULL\n",
    "\n",
    "# Each matrix corresponds to iterations for honest/dishonest forest given DGP 1-4\n",
    "tau.estims_h1  <- mat1[1,c(seq(1,ncol(mat1),by=2))]\n",
    "tau.estims_nh1 <- mat1[1,c(seq(2,ncol(mat1),by=2))]\n",
    "\n",
    "tau.estims_h2  <- mat1[2,c(seq(1,ncol(mat1),by=2))]\n",
    "tau.estims_nh2 <- mat1[2,c(seq(2,ncol(mat1),by=2))]\n",
    "\n",
    "tau.estims_h3  <- mat1[3,c(seq(1,ncol(mat1),by=2))]\n",
    "tau.estims_nh3 <- mat1[3,c(seq(2,ncol(mat1),by=2))]\n",
    "\n",
    "tau.estims_h4  <- mat1[4,c(seq(1,ncol(mat1),by=2))]\n",
    "tau.estims_nh4 <- mat1[4,c(seq(2,ncol(mat1),by=2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97679f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-07T23:55:27.832614Z",
     "start_time": "2022-08-07T23:55:27.705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mean of tau estimates across all repetitions \n",
    "\n",
    "###### Mean\n",
    "honest_1  <- mean(tau.estims_h1)\n",
    "nhonest_1 <- mean(tau.estims_nh1)\n",
    "\n",
    "honest_2  <- mean(tau.estims_h2)\n",
    "nhonest_2 <- mean(tau.estims_nh2)\n",
    "\n",
    "honest_3  <- mean(tau.estims_h3)\n",
    "nhonest_3 <- mean(tau.estims_nh3)\n",
    "\n",
    "honest_4  <- mean(tau.estims_h4)\n",
    "nhonest_4 <- mean(tau.estims_nh4)\n",
    "\n",
    "######## Bias \n",
    "honest_1_bias  <- mean(tau.estims_h1 - tau)\n",
    "nhonest_1_bias <- mean(tau.estims_nh1 - tau)\n",
    "\n",
    "honest_2_bias  <- mean(tau.estims_h2 - tau)\n",
    "nhonest_2_bias <- mean(tau.estims_nh2 - tau)\n",
    "\n",
    "honest_3_bias <- mean(tau.estims_h3 - tau)\n",
    "nhonest_3_bias <- mean(tau.estims_nh3 - tau)\n",
    "\n",
    "honest_4_bias  <- mean(tau.estims_h4 - tau)\n",
    "nhonest_4_bias <- mean(tau.estims_nh4 - tau)\n",
    "\n",
    "bias_ate <- rbind(cbind(honest_1_bias,nhonest_1_bias),\n",
    "                  cbind(honest_2_bias,nhonest_2_bias),\n",
    "                  cbind(honest_3_bias,nhonest_3_bias),\n",
    "                  cbind(honest_4_bias,nhonest_4_bias))\n",
    "                  \n",
    "\n",
    "######### Variance \n",
    "honest_1_var  <- mean((tau.estims_h1 - mean(tau.estims_h1))^2)\n",
    "nhonest_1_var <- mean((tau.estims_nh1 - mean(tau.estims_nh1))^2)\n",
    "\n",
    "honest_2_var <- mean((tau.estims_h2 - mean(tau.estims_h2))^2)\n",
    "nhonest_2_var <- mean((tau.estims_nh2 - mean(tau.estims_nh2))^2)\n",
    "\n",
    "honest_3_var <- mean((tau.estims_h3 - mean(tau.estims_h3))^2)\n",
    "nhonest_3_var <- mean((tau.estims_nh3 - mean(tau.estims_nh3))^2)\n",
    "\n",
    "honest_4_var  <- mean((tau.estims_h4 - mean(tau.estims_h4))^2)\n",
    "nhonest_4_var <- mean((tau.estims_nh4 - mean(tau.estims_nh4))^2)\n",
    "\n",
    "\n",
    "var_ate <- rbind(cbind(honest_1_var,nhonest_1_var),\n",
    "                  cbind(honest_2_var,nhonest_2_var),\n",
    "                  cbind(honest_3_var,nhonest_3_var),\n",
    "                  cbind(honest_4_var,nhonest_4_var))\n",
    "\n",
    "\n",
    "######### MSE \n",
    "honest_1_mse  <- mean((tau.estims_h1 - tau)^2) \n",
    "nhonest_1_mse <- mean((tau.estims_nh1 - tau)^2) \n",
    "\n",
    "honest_2_mse <- mean((tau.estims_h2 - tau)^2) \n",
    "nhonest_2_mse <- mean((tau.estims_nh2 - tau)^2) \n",
    "\n",
    "honest_3_mse <- mean((tau.estims_h3 - tau)^2) \n",
    "nhonest_3_mse <- mean((tau.estims_nh3 - tau)^2) \n",
    "\n",
    "honest_4_mse  <- mean((tau.estims_h4 - tau)^2) \n",
    "nhonest_4_mse <- mean((tau.estims_nh4 - tau)^2) \n",
    "\n",
    "mse_ate <- rbind(cbind(honest_1_mse,nhonest_1_mse),\n",
    "                  cbind(honest_2_mse,nhonest_2_mse),\n",
    "                  cbind(honest_3_mse,nhonest_3_mse),\n",
    "                  cbind(honest_4_mse,nhonest_4_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ec89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.frame(cbind(\"Bias\" = round(bias_ate*100,2), \n",
    "                                \"VAR\" = round(var_ate*100,2),\n",
    "                                \"MSE\" = round(mse_ate*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5daaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ate <- data.frame(cbind(\"Bias\" = round(bias_ate*100,2), \n",
    "                                \"VAR\" = round(var_ate*100,2),\n",
    "                                \"MSE\" = round(mse_ate*100,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16427e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-07T23:55:29.317650Z",
     "start_time": "2022-08-07T23:55:29.284Z"
    }
   },
   "outputs": [],
   "source": [
    "results_ate_latex <- cbind(results_ate[,1],results_ate[,3],results_ate[,5],\n",
    "                           results_ate[,2],results_ate[,4],results_ate[,6])\n",
    "\n",
    "#print.xtable(xtable(head(results_ate_latex)), file = \"./Data.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e01bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T00:05:04.181742Z",
     "start_time": "2022-08-08T00:04:58.010Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the distribution of scaled estimation for Honest and Dishonest Forest across all 5 DGPs.\n",
    "\n",
    "# Honest Forest Case 1\n",
    "df_h1 = data.frame('tau.estims_h1' = tau.estims_h1 - 1)\n",
    "sd_h1 = sd(tau.estims_h1)\n",
    "\n",
    "df_h1 = data.frame(\"tau.estims_h1\" = df_h1$tau.estims_h1/sd_h1)\n",
    "\n",
    "figa = ggplot(df_h1, aes(x = tau.estims_h1)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01) + \n",
    "        ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(size=30,face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "figa\n",
    "\n",
    "# Dishonest Forest Case 1\n",
    "df_nh1 = data.frame('tau.estims_nh1' = tau.estims_nh1 - 1)\n",
    "sd_nh1 = sd(tau.estims_nh1)\n",
    "\n",
    "df_nh1 = data.frame(\"tau.estims_nh1\" = df_nh1$tau.estims_nh1/sd_nh1)\n",
    "\n",
    "figb = ggplot(df_nh1, aes(x = tau.estims_nh1)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01) + \n",
    "        ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(size=30,face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "figb\n",
    "\n",
    "# Honest Forest Case 2\n",
    "df_h2 = data.frame('tau.estims_h2' = tau.estims_h2 - 1)\n",
    "sd_h2 = sd(tau.estims_h2)\n",
    "\n",
    "df_h2 = data.frame(\"tau.estims_h2\" = df_h2$tau.estims_h2/sd_h2)\n",
    "\n",
    "figc = ggplot(df_h2, aes(x = tau.estims_h2)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01)  \n",
    "        #ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "figc\n",
    "\n",
    "# Dishonest Forest Case 2\n",
    "df_nh2 = data.frame('tau.estims_nh2' = tau.estims_nh2 - 1)\n",
    "sd_nh2 = sd(tau.estims_nh2)\n",
    "\n",
    "df_nh2 = data.frame(\"tau.estims_nh2\" = df_nh2$tau.estims_nh2/sd_nh2)\n",
    "\n",
    "figd = ggplot(df_nh2, aes(x = tau.estims_nh2)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01)  \n",
    "       # ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "figd\n",
    "\n",
    "# Honest Forest Case 3\n",
    "df_h3 = data.frame('tau.estims_h3' = tau.estims_h3 - 1)\n",
    "sd_h3 = sd(tau.estims_h3)\n",
    "\n",
    "df_h3 = data.frame(\"tau.estims_h3\" = df_h3$tau.estims_h3/sd_h3)\n",
    "\n",
    "fige = ggplot(df_h3, aes(x = tau.estims_h3)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01)  \n",
    "        #ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "fige\n",
    "\n",
    "# Dishonest Forest Case 3\n",
    "df_nh3 = data.frame('tau.estims_nh3' = tau.estims_nh3 - 1)\n",
    "sd_nh3 = sd(tau.estims_nh3)\n",
    "\n",
    "df_nh3 = data.frame(\"tau.estims_nh3\" = df_nh3$tau.estims_nh3/sd_nh3)\n",
    "\n",
    "figf = ggplot(df_nh3, aes(x = tau.estims_nh3)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01) \n",
    "        #ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "figf\n",
    "\n",
    "# Honest Forest Case 4\n",
    "df_h4 = data.frame('tau.estims_h4' = tau.estims_h4 - 1)\n",
    "sd_h4 = sd(tau.estims_h4)\n",
    "\n",
    "df_h4 = data.frame(\"tau.estims_h4\" = df_h4$tau.estims_h4/sd_h4)\n",
    "\n",
    "figg = ggplot(df_h4, aes(x = tau.estims_h4)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01) \n",
    "       # ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "figg\n",
    "\n",
    "# Dishonest Forest Case 4\n",
    "df_nh4 = data.frame('tau.estims_nh4' = tau.estims_nh4 - 1)\n",
    "sd_nh4 = sd(tau.estims_nh4)\n",
    "\n",
    "df_nh4 = data.frame(\"tau.estims_nh4\" = df_nh4$tau.estims_nh4/sd_nh4)\n",
    "\n",
    "figh = ggplot(df_nh4, aes(x = tau.estims_nh4)) +\n",
    "        geom_histogram(aes(y=..density..), bins = 100, fill = \"royalblue3\", alpha = 0.3, color = \"dark blue\") +\n",
    "        geom_vline(aes(xintercept = 0), col = \"black\") +\n",
    "        xlim(c(-10, 10)) + xlab(\"\") + ylab(\"\") + theme_minimal() + \n",
    "        theme(plot.title = element_text(color=\"black\", face=\"bold\", size=30),axis.text=element_text(size=20)) +\n",
    "        stat_function(fun = dnorm, args = list(mean = 0, sd = 1), geom = \"area\", col = \"red\", fill = \"red\", alpha = 0.01)  \n",
    "       # ggtitle(paste0(\"Scaled Estimation Error n = \", 200, \", p = \", 30)) + theme(plot.title = element_text(face=\"bold\", hjust = 0.5))\n",
    "options(repr.plot.width=30, repr.plot.height=14)\n",
    "\n",
    "figh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060d681",
   "metadata": {},
   "source": [
    "### 2.3. Causal Forests, Double Machine Learning, and Post Double Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO Estimation Function\n",
    "est_lasso <- function(obj_dml_data) {\n",
    "    \n",
    "   # set.seed(70)\n",
    "    learner <- lrn(\"regr.cv_glmnet\", s=\"lambda.min\")\n",
    "    g_hat <- learner$clone()                                  # use LASSO to estimate nuisance g() and m()\n",
    "    m_hat <- learner$clone()\n",
    "    \n",
    "    DML_PLR  <- DoubleMLPLR$new(obj_dml_data, g_hat, m_hat)   # initialize the DML Partially Linear Model \n",
    "    DML_PLR$fit()                                             # Fit the model and extract coefficient estimates\n",
    "    theta_hat <- DML_PLR$coef\n",
    "    sd_hat    <- DML_PLR$se\n",
    "    params    <- cbind(theta_hat,sd_hat)\n",
    "    return(params)\n",
    "}\n",
    "\n",
    "est_rforest <- function(obj_dml_data) {\n",
    "    \n",
    "   # set.seed(70)\n",
    "    learner <- lrn(\"regr.ranger\", num.trees=100, min.node.size=2, max.depth=5)\n",
    "    g_hat <- learner$clone()                                  # use LASSO to estimate nuisance g() and m()\n",
    "    m_hat <- learner$clone()\n",
    "    \n",
    "    DML_PLR  <- DoubleMLPLR$new(obj_dml_data, g_hat, m_hat)   # initialize the DML Partially Linear Model \n",
    "    DML_PLR$fit()                                             # Fit the model and extract coefficient estimates\n",
    "    theta_hat <- DML_PLR$coef\n",
    "    sd_hat    <- DML_PLR$se\n",
    "    params    <- cbind(theta_hat,sd_hat)\n",
    "    return(params)\n",
    "}\n",
    "\n",
    "\n",
    "sim_function1 <- function(data){\n",
    "    \n",
    "    DML_data     <- double_ml_data_from_data_frame(data, y_col = \"Y\", d_cols = \"W\")\n",
    "    param_output <- est_lasso(DML_data) \n",
    "    return(param_output)\n",
    "}\n",
    "\n",
    "sim_function2 <- function(data){\n",
    "    \n",
    "    DML_data     <- double_ml_data_from_data_frame(data, y_col = \"Y\", d_cols = \"W\")\n",
    "    param_output <- est_rforest(DML_data) \n",
    "    return(param_output)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a08b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)     # random seed for replicability of results \n",
    "mse.reps <- 1000    # number of repetitions: set to 1000\n",
    "n <- 200          # number of observations\n",
    "p <- c(30, 50, 100, 200)           # number of covariates\n",
    "tau <- 1          # true treatment effect is constant in all setups\n",
    "\n",
    "# DGPs with different levels of confounding \n",
    "dgp <- c(\"nw2\",\"aw1\",\"nw1\",\"nw3\")\n",
    "grid <- expand.grid(n = n, p = p, dgp = dgp, stringsAsFactors = FALSE)\n",
    "var_matrix <- matrix(NA, ncol = length(n)*length(p), nrow = mse.reps)\n",
    "\n",
    "# Function to apply GRF on DGPs and output estimates of tau\n",
    "out <- lapply(1:nrow(grid), function(i) {\n",
    "  n <- grid$n[i]\n",
    "  p <- grid$p[i]\n",
    "  dgp <- grid$dgp[i]\n",
    "  tau.hat <- replicate(mse.reps, {\n",
    "    data <- generate_DGP(n = n, p = p, dgp = dgp, sigma.tau = 1)\n",
    "    theta_estim1 <- sim_function1(data$dmldat)[1]  \n",
    "    theta_estim2 <- sim_function2(data$dmldat)[1] \n",
    "    cf_honest   <- causal_forest(data$X, data$Y, data$W, honesty = TRUE)    # honest forest\n",
    "    tau_honest  <- suppressWarnings(average_treatment_effect(cf_honest))[1]\n",
    "    DS          <- summary(rlassoEffect(x = data$X, y = data$Y, d=data$W, method = \"double selection\"))$coefficients[1,1]\n",
    "\n",
    "    tau_estims <- cbind(tau_honest,theta_estim1,theta_estim2,DS)\n",
    "\n",
    "  })\n",
    "\n",
    "  data.frame(dgp = dgp, p = p, n = n, C.GRF = tau.hat)\n",
    "})\n",
    "\n",
    "# Dataframe containing estimates of tau across all simulations\n",
    "tau_table_comp <- do.call(rbind, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55aceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate large data into separate dataframes\n",
    "tau_all <- tau_table_comp\n",
    "tau_all <- tau_all[order(tau_all$p),]\n",
    "\n",
    "dim_30  <- tau_all[1:4,]\n",
    "dim_50  <- tau_all[5:8,]\n",
    "dim_100 <- tau_all[9:12,]\n",
    "dim_200 <- tau_all[13:16,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate collective results into separate matrices\n",
    "mat_comp_30 <- as.matrix(dim_30[,4:ncol(dim_30)])\n",
    "colnames(mat_comp_30) <- NULL\n",
    "rownames(mat_comp_30) <- NULL\n",
    "\n",
    "# Each matrix corresponds to iterations for honest/dishonest forest given DGP 1-6\n",
    "estims_grf_30 <- cbind(mat_comp_30[1,c(seq(1,ncol(mat_comp_30),by=4))],\n",
    "                       mat_comp_30[2,c(seq(1,ncol(mat_comp_30),by=4))],\n",
    "                       mat_comp_30[3,c(seq(1,ncol(mat_comp_30),by=4))],\n",
    "                       mat_comp_30[4,c(seq(1,ncol(mat_comp_30),by=4))])\n",
    "\n",
    "estims_dmll_30 <- cbind(mat_comp_30[1,c(seq(2,ncol(mat_comp_30),by=4))],\n",
    "                        mat_comp_30[2,c(seq(2,ncol(mat_comp_30),by=4))],\n",
    "                        mat_comp_30[3,c(seq(2,ncol(mat_comp_30),by=4))],\n",
    "                        mat_comp_30[4,c(seq(2,ncol(mat_comp_30),by=4))])\n",
    "\n",
    "estims_dmlr_30 <- cbind(mat_comp_30[1,c(seq(3,ncol(mat_comp_30),by=4))],\n",
    "                        mat_comp_30[2,c(seq(3,ncol(mat_comp_30),by=4))],\n",
    "                        mat_comp_30[3,c(seq(3,ncol(mat_comp_30),by=4))],\n",
    "                        mat_comp_30[4,c(seq(3,ncol(mat_comp_30),by=4))])\n",
    "\n",
    "estims_pds_30 <- cbind(mat_comp_30[1,c(seq(4,ncol(mat_comp_30),by=4))],\n",
    "                       mat_comp_30[2,c(seq(4,ncol(mat_comp_30),by=4))],\n",
    "                       mat_comp_30[3,c(seq(4,ncol(mat_comp_30),by=4))],\n",
    "                       mat_comp_30[4,c(seq(4,ncol(mat_comp_30),by=4))])\n",
    "\n",
    "# Separate collective results into separate matrices\n",
    "mat_comp_50 <- as.matrix(dim_50[,4:ncol(dim_50)])\n",
    "colnames(mat_comp_50) <- NULL\n",
    "rownames(mat_comp_50) <- NULL\n",
    "\n",
    "# Each matrix corresponds to iterations for honest/dishonest forest given DGP 1-4\n",
    "estims_grf_50 <- cbind(mat_comp_50[1,c(seq(1,ncol(mat_comp_50),by=4))],\n",
    "                       mat_comp_50[2,c(seq(1,ncol(mat_comp_50),by=4))],\n",
    "                       mat_comp_50[3,c(seq(1,ncol(mat_comp_50),by=4))],\n",
    "                       mat_comp_50[4,c(seq(1,ncol(mat_comp_50),by=4))])\n",
    "\n",
    "estims_dmll_50 <- cbind(mat_comp_50[1,c(seq(2,ncol(mat_comp_50),by=4))],\n",
    "                        mat_comp_50[2,c(seq(2,ncol(mat_comp_50),by=4))],\n",
    "                        mat_comp_50[3,c(seq(2,ncol(mat_comp_50),by=4))],\n",
    "                        mat_comp_50[4,c(seq(2,ncol(mat_comp_50),by=4))])\n",
    "\n",
    "estims_dmlr_50 <- cbind(mat_comp_50[1,c(seq(3,ncol(mat_comp_50),by=4))],\n",
    "                        mat_comp_50[2,c(seq(3,ncol(mat_comp_50),by=4))],\n",
    "                        mat_comp_50[3,c(seq(3,ncol(mat_comp_50),by=4))],\n",
    "                        mat_comp_50[4,c(seq(3,ncol(mat_comp_50),by=4))])\n",
    "\n",
    "estims_pds_50 <- cbind(mat_comp_50[1,c(seq(4,ncol(mat_comp_50),by=4))],\n",
    "                       mat_comp_50[2,c(seq(4,ncol(mat_comp_50),by=4))],\n",
    "                       mat_comp_50[3,c(seq(4,ncol(mat_comp_50),by=4))],\n",
    "                       mat_comp_50[4,c(seq(4,ncol(mat_comp_50),by=4))])\n",
    "\n",
    "# Separate collective results into separate matrices\n",
    "mat_comp_100 <- as.matrix(dim_100[,4:ncol(dim_100)])\n",
    "colnames(mat_comp_100) <- NULL\n",
    "rownames(mat_comp_100) <- NULL\n",
    "\n",
    "# Each matrix corresponds to iterations for honest/dishonest forest given DGP 1-4\n",
    "estims_grf_100 <- cbind(mat_comp_100[1,c(seq(1,ncol(mat_comp_100),by=4))],\n",
    "                        mat_comp_100[2,c(seq(1,ncol(mat_comp_100),by=4))],\n",
    "                        mat_comp_100[3,c(seq(1,ncol(mat_comp_100),by=4))],\n",
    "                        mat_comp_100[4,c(seq(1,ncol(mat_comp_100),by=4))])\n",
    "\n",
    "estims_dmll_100 <- cbind(mat_comp_100[1,c(seq(2,ncol(mat_comp_100),by=4))],\n",
    "                         mat_comp_100[2,c(seq(2,ncol(mat_comp_100),by=4))],\n",
    "                         mat_comp_100[3,c(seq(2,ncol(mat_comp_100),by=4))],\n",
    "                         mat_comp_100[4,c(seq(2,ncol(mat_comp_100),by=4))])\n",
    "\n",
    "estims_dmlr_100 <- cbind(mat_comp_100[1,c(seq(3,ncol(mat_comp_100),by=4))],\n",
    "                         mat_comp_100[2,c(seq(3,ncol(mat_comp_100),by=4))],\n",
    "                         mat_comp_100[3,c(seq(3,ncol(mat_comp_100),by=4))],\n",
    "                         mat_comp_100[4,c(seq(3,ncol(mat_comp_100),by=4))])\n",
    "\n",
    "estims_pds_100 <- cbind(mat_comp_100[1,c(seq(4,ncol(mat_comp_100),by=4))],\n",
    "                        mat_comp_100[2,c(seq(4,ncol(mat_comp_100),by=4))],\n",
    "                        mat_comp_100[3,c(seq(4,ncol(mat_comp_100),by=4))],\n",
    "                        mat_comp_100[4,c(seq(4,ncol(mat_comp_100),by=4))])\n",
    "\n",
    "# Separate collective results into separate matrices\n",
    "mat_comp_200 <- as.matrix(dim_200[,4:ncol(dim_200)])\n",
    "colnames(mat_comp_200) <- NULL\n",
    "rownames(mat_comp_200) <- NULL\n",
    "\n",
    "# Each matrix corresponds to iterations for honest/dishonest forest given DGP 1-4\n",
    "estims_grf_200 <- cbind(mat_comp_200[1,c(seq(1,ncol(mat_comp_200),by=4))],\n",
    "                        mat_comp_200[2,c(seq(1,ncol(mat_comp_200),by=4))],\n",
    "                        mat_comp_200[3,c(seq(1,ncol(mat_comp_200),by=4))],\n",
    "                        mat_comp_200[4,c(seq(1,ncol(mat_comp_200),by=4))])\n",
    "\n",
    "estims_dmll_200 <- cbind(mat_comp_200[1,c(seq(2,ncol(mat_comp_200),by=4))],\n",
    "                         mat_comp_200[2,c(seq(2,ncol(mat_comp_200),by=4))],\n",
    "                         mat_comp_200[3,c(seq(2,ncol(mat_comp_200),by=4))],\n",
    "                         mat_comp_200[4,c(seq(2,ncol(mat_comp_200),by=4))])\n",
    "\n",
    "estims_dmlr_200 <- cbind(mat_comp_200[1,c(seq(3,ncol(mat_comp_200),by=4))],\n",
    "                         mat_comp_200[2,c(seq(3,ncol(mat_comp_200),by=4))],\n",
    "                         mat_comp_200[3,c(seq(3,ncol(mat_comp_200),by=4))],\n",
    "                         mat_comp_200[4,c(seq(3,ncol(mat_comp_200),by=4))])\n",
    "\n",
    "estims_pds_200 <- cbind(mat_comp_200[1,c(seq(4,ncol(mat_comp_200),by=4))],\n",
    "                        mat_comp_200[2,c(seq(4,ncol(mat_comp_200),by=4))],\n",
    "                        mat_comp_200[3,c(seq(4,ncol(mat_comp_200),by=4))],\n",
    "                        mat_comp_200[4,c(seq(4,ncol(mat_comp_200),by=4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171875f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of tau estimates across all repetitions \n",
    "bias_table_30    <- matrix(NA, nrow = 4, ncol = 4)\n",
    "var_table_30     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "mse_table_30     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "\n",
    "bias_table_50    <- matrix(NA, nrow = 4, ncol = 4)\n",
    "var_table_50     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "mse_table_50     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "\n",
    "bias_table_100    <- matrix(NA, nrow = 4, ncol = 4)\n",
    "var_table_100     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "mse_table_100     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "\n",
    "bias_table_200    <- matrix(NA, nrow = 4, ncol = 4)\n",
    "var_table_200     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "mse_table_200     <- matrix(NA, nrow = 4, ncol = 4)\n",
    "\n",
    "\n",
    "for (i in 1:4) {\n",
    "    \n",
    "    bias_table_30[i,1] <- mean(estims_grf_30[,i] - tau)\n",
    "    bias_table_30[i,2] <- mean(estims_dmll_30[,i] - tau)\n",
    "    bias_table_30[i,3] <- mean(estims_dmlr_30[,i] - tau)\n",
    "    bias_table_30[i,4] <- mean(estims_pds_30[,i] - tau)\n",
    "    \n",
    "    bias_table_50[i,1] <- mean(estims_grf_50[,i] - tau)\n",
    "    bias_table_50[i,2] <- mean(estims_dmll_50[,i] - tau)\n",
    "    bias_table_50[i,3] <- mean(estims_dmlr_50[,i] - tau)\n",
    "    bias_table_50[i,4] <- mean(estims_pds_50[,i] - tau)\n",
    "    \n",
    "    bias_table_100[i,1] <- mean(estims_grf_100[,i] - tau)\n",
    "    bias_table_100[i,2] <- mean(estims_dmll_100[,i] - tau)\n",
    "    bias_table_100[i,3] <- mean(estims_dmlr_100[,i] - tau)\n",
    "    bias_table_100[i,4] <- mean(estims_pds_100[,i] - tau)\n",
    "    \n",
    "    bias_table_200[i,1] <- mean(estims_grf_200[,i] - tau)\n",
    "    bias_table_200[i,2] <- mean(estims_dmll_200[,i] - tau)\n",
    "    bias_table_200[i,3] <- mean(estims_dmlr_200[,i] - tau)\n",
    "    bias_table_200[i,4] <- mean(estims_pds_200[,i] - tau)\n",
    "    \n",
    "    var_table_30[i,1] <- mean((estims_grf_30[,i] - mean(estims_grf_30[,i]))^2)\n",
    "    var_table_30[i,2] <- mean((estims_dmll_30[,i] - mean(estims_dmll_30[,i]))^2)\n",
    "    var_table_30[i,3] <- mean((estims_dmlr_30[,i] - mean(estims_dmlr_30[,i]))^2)\n",
    "    var_table_30[i,4] <- mean((estims_pds_30[,i] - mean(estims_pds_30[,i]))^2)\n",
    "    \n",
    "    var_table_50[i,1] <- mean((estims_grf_50[,i] - mean(estims_grf_50[,i]))^2)\n",
    "    var_table_50[i,2] <- mean((estims_dmll_50[,i] - mean(estims_dmll_50[,i]))^2)\n",
    "    var_table_50[i,3] <- mean((estims_dmlr_50[,i] - mean(estims_dmlr_50[,i]))^2)\n",
    "    var_table_50[i,4] <- mean((estims_pds_50[,i] - mean(estims_pds_50[,i]))^2)\n",
    "          \n",
    "    var_table_100[i,1] <- mean((estims_grf_100[,i] - mean(estims_grf_100[,i]))^2)\n",
    "    var_table_100[i,2] <- mean((estims_dmll_100[,i] - mean(estims_dmll_100[,i]))^2)\n",
    "    var_table_100[i,3] <- mean((estims_dmlr_100[,i] - mean(estims_dmlr_100[,i]))^2)\n",
    "    var_table_100[i,4] <- mean((estims_pds_100[,i] - mean(estims_pds_100[,i]))^2)\n",
    "        \n",
    "    var_table_200[i,1] <- mean((estims_grf_200[,i] - mean(estims_grf_200[,i]))^2)\n",
    "    var_table_200[i,2] <- mean((estims_dmll_200[,i] - mean(estims_dmll_200[,i]))^2)\n",
    "    var_table_200[i,3] <- mean((estims_dmlr_200[,i] - mean(estims_dmlr_200[,i]))^2)\n",
    "    var_table_200[i,4] <- mean((estims_pds_200[,i] - mean(estims_pds_200[,i]))^2)\n",
    "    \n",
    "    mse_table_30[i,1] <- mean((estims_grf_30[,i] - tau)^2) \n",
    "    mse_table_30[i,2] <- mean((estims_dmll_30[,i] - tau)^2) \n",
    "    mse_table_30[i,3] <- mean((estims_dmlr_30[,i] - tau)^2)\n",
    "    mse_table_30[i,4] <- mean((estims_pds_30[,i] - tau)^2) \n",
    "    \n",
    "    mse_table_50[i,1] <- mean((estims_grf_50[,i] - tau)^2) \n",
    "    mse_table_50[i,2] <- mean((estims_dmll_50[,i] - tau)^2) \n",
    "    mse_table_50[i,3] <- mean((estims_dmlr_50[,i] - tau)^2)\n",
    "    mse_table_50[i,4] <- mean((estims_pds_50[,i] - tau)^2)\n",
    "                              \n",
    "    mse_table_100[i,1] <- mean((estims_grf_100[,i] - tau)^2) \n",
    "    mse_table_100[i,2] <- mean((estims_dmll_100[,i] - tau)^2) \n",
    "    mse_table_100[i,3] <- mean((estims_dmlr_100[,i] - tau)^2)\n",
    "    mse_table_100[i,4] <- mean((estims_pds_100[,i] - tau)^2)\n",
    "                              \n",
    "    mse_table_200[i,1] <- mean((estims_grf_200[,i] - tau)^2) \n",
    "    mse_table_200[i,2] <- mean((estims_dmll_200[,i] - tau)^2) \n",
    "    mse_table_200[i,3] <- mean((estims_dmlr_200[,i] - tau)^2)\n",
    "    mse_table_200[i,4] <- mean((estims_pds_200[,i] - tau)^2)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e264fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_table_30 <- round(bias_table_30*10,3) \n",
    "var_table_30 <- round(var_table_30*10,3) \n",
    "mse_table_30 <- round(mse_table_30* 10,3) \n",
    "\n",
    "bias_table_50 <- round(bias_table_50*10,3) \n",
    "var_table_50 <- round(var_table_50*10,3) \n",
    "mse_table_50 <- round(mse_table_50* 10,3) \n",
    "\n",
    "bias_table_100 <- round(bias_table_100*10,3) \n",
    "var_table_100 <- round(var_table_100*10,3) \n",
    "mse_table_100 <- round(mse_table_100* 10,3) \n",
    "\n",
    "bias_table_200 <- round(bias_table_200*10,3) \n",
    "var_table_200  <- round(var_table_200*10 ,3) \n",
    "mse_table_200  <- round(mse_table_200 * 10,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f93ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gdp_30 <- cbind(bias_table_30[,1],var_table_30[,1],mse_table_30[,1],\n",
    "                        bias_table_30[,2],var_table_30[,2],mse_table_30[,2],\n",
    "                        bias_table_30[,3],var_table_30[,3],mse_table_30[,3],\n",
    "                        bias_table_30[,4],var_table_30[,4],mse_table_30[,4])\n",
    "\n",
    "results_gdp_50 <- cbind(bias_table_50[,1],var_table_50[,1],mse_table_50[,1],\n",
    "                        bias_table_50[,2],var_table_50[,2],mse_table_50[,2],\n",
    "                        bias_table_50[,3],var_table_50[,3],mse_table_50[,3],\n",
    "                        bias_table_50[,4],var_table_50[,4],mse_table_50[,4])\n",
    "\n",
    "results_gdp_100 <- cbind(bias_table_100[,1],var_table_100[,1],mse_table_100[,1],\n",
    "                         bias_table_100[,2],var_table_100[,2],mse_table_100[,2],\n",
    "                         bias_table_100[,3],var_table_100[,3],mse_table_100[,3],\n",
    "                         bias_table_100[,4],var_table_100[,4],mse_table_100[,4])\n",
    "\n",
    "results_gdp_200 <- cbind(bias_table_200[,1],var_table_200[,1],mse_table_200[,1],\n",
    "                         bias_table_200[,2],var_table_200[,2],mse_table_200[,2],\n",
    "                         bias_table_200[,3],var_table_200[,3],mse_table_200[,3],\n",
    "                         bias_table_200[,4],var_table_200[,4],mse_table_200[,4])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5496c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the results locally\n",
    "#print.xtable(xtable(head(results_gdp_30), digits = 2), file = \"./results_gdp_30\")\n",
    "#print.xtable(xtable(head(results_gdp_50), digits = 2), file = \"./results_gdp_50\")\n",
    "#print.xtable(xtable(head(results_gdp_100), digits = 2), file = \"./results_gdp_100\")\n",
    "#print.xtable(xtable(head(results_gdp_200), digits = 2), file = \"./results_gdp_200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca5a50",
   "metadata": {},
   "source": [
    "### 3. Predicting HTEs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9967f",
   "metadata": {},
   "source": [
    "### 3.1. Data Generating Process 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a59f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T18:12:14.970701Z",
     "start_time": "2022-08-15T18:12:14.945Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_data_het <- function(n, p, sigma.m = 1, sigma.tau = 0.1, sigma.noise = 1,\n",
    "                                 dgp = c(\"aw1\", \"aw3\", \"ai2\",\n",
    "                                         \"nw1\", \"nw2\", \"nw3\")) {\n",
    "  # To add an additonal DGP, fill in the template below and add an entry to `dgp` and `.minp`.\n",
    "  .minp <- c(aw1=2, aw3=1, ai2=6, nw1=5, nw2=5, nw3=3, nw4=5)\n",
    "  dgp <- match.arg(dgp)\n",
    "  minp <- .minp[dgp]\n",
    "  if (p < minp) {\n",
    "    msg <- paste0(\"Selected dgp \", dgp, \" requires a minimum of \", minp, \" variables.\")\n",
    "    stop(msg)\n",
    "  }\n",
    "\n",
    "  # Create data\n",
    "    if (dgp == \"aw1\") {\n",
    "    # equation (27) of https://arxiv.org/pdf/1510.04342.pdf\n",
    "    X <- matrix(runif(n * p, min = 0, max = 1), n, p)\n",
    "    tau <- rep(0, n)  # Treatment effect is zero\n",
    "    e <- (1 / 4)  * (exp(X[,3]) /(1 + exp(X[,3])))\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- 2 * X[, 1] - 1 + e * tau\n",
    "    V <- 1\n",
    "  } else if (dgp == \"aw3\") {\n",
    "    # section 6.2 in https://arxiv.org/pdf/1610.01271.pdf\n",
    "    # (confounding from aw1, tau from aw2)\n",
    "    X <- matrix(runif(n * p), n, p)\n",
    "    zeta1 <- 1 + 1 / (1 + exp(-20 * (X[, 1] - (1 / 3))))\n",
    "    zeta2 <- 1 + 1 / (1 + exp(-20 * (X[, 2] - (1 / 3))))\n",
    "    tau <- zeta1 * zeta2\n",
    "    e <- (1 / 4)  * (exp(X[,3]) /(1 + exp(X[,3])))\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- 2 * X[, 1] - 1 + e * tau\n",
    "    V <- 1\n",
    "  } else if (dgp == \"ai2\") {\n",
    "    X <- matrix(runif(n * p), n, p)\n",
    "    nu_x <- 0.5 * X[, 1] + 0.5 * X[, 2] + X[, 3] + X[, 4] + X[, 5] + X[, 6]\n",
    "    tau <- 0.5 * ((X[, 1] > 0) * X[, 1] + (X[, 2] > 0) * X[, 2])\n",
    "    e <- rep(0.5, n)\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- nu_x + e * tau\n",
    "    V <- 0.1^2\n",
    "  } else if (dgp == \"nw1\") {\n",
    "    # \"Setup A\" from Section 4 of https://arxiv.org/pdf/1712.04912.pdf\n",
    "    # Difficult nuisance components, easy treatment effect function.\n",
    "    X <- matrix(runif(n * p), n, p)\n",
    "    tau <- (X[, 1] + X[, 2]) / 2\n",
    "    eta <- 0.1\n",
    "    e <- pmax(eta, pmin(sin(pi * X[, 1] * X[, 2]), 1 - eta))\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- sin(pi * X[, 1] * X[, 2]) + 2 * (X[, 3] - 0.5)^2 + X[, 4] + 0.5 * X[, 5] + e * tau\n",
    "    V <- 1\n",
    "  } else if (dgp == \"nw2\") {\n",
    "    # \"Setup B\" from Section 4 of https://arxiv.org/pdf/1712.04912.pdf\n",
    "    # Randomized trial\n",
    "    X <- matrix(runif(n * p), n, p)\n",
    "    tau <- X[,1] + log(1 + exp(X[, 2]))\n",
    "    e <- rep(0.5, n)\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- pmax(0, X[, 1] + X[, 2], X[, 3]) + pmax(0, X[, 4] + X[, 5]) + e * tau\n",
    "    V <- 1\n",
    "  } else if (dgp == \"nw3\") {\n",
    "    # \"Setup C\" from Section 4 of https://arxiv.org/pdf/1712.04912.pdf\n",
    "    # Easy propensity score, strong confounding, difficult baseline,\n",
    "    # constant treatment effect\n",
    "    X <- matrix(runif(n * p), n, p)\n",
    "    tau <- X[,1] + log(1 + exp(X[, 2]))\n",
    "    e <- 1 / (1 + exp(X[, 2] + X[, 3]))\n",
    "    W <- rbinom(n = n, size = 1, prob = e)\n",
    "    m <- 2 * log(1 + exp(X[, 1] + X[, 2] + X[, 3])) + e * tau\n",
    "    V <- 1\n",
    "  } \n",
    "\n",
    "  # Scale and return data (rescale if `m` and `tau` is not constant, the NA check is for when n=1)\n",
    "  if (!is.na(sd(m)) & !(sd(m) == 0)) {\n",
    "    m <- m / sd(m) * sigma.m\n",
    "  }\n",
    "  if (!is.na(sd(tau)) & !(sd(tau) == 0)) {\n",
    "    tau <- tau / sd(tau) * sigma.tau\n",
    "  }\n",
    "  V <- V / mean(V) * sigma.noise^2\n",
    "  Y <- m + (W - e) * tau + sqrt(V) * rnorm(n)\n",
    "  out <- list(X = X, Y = Y, W = W, tau = tau, m = m, e = e, dgp = dgp)\n",
    "\n",
    "  out\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be660ae",
   "metadata": {},
   "source": [
    "### 3.2. Simulation Experiments: Honest and Dishonest Forests for HTEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4162103",
   "metadata": {},
   "source": [
    "### Honest Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabdd31",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-15T18:12:18.108Z"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "mse.reps <- 100    # Number of repetitions: Set to 100\n",
    "n <- c(100, 200, 300)\n",
    "p <- c(10, 50, 100, 300)\n",
    "\n",
    "dgp <- c(\"nw2\",\"ai2\",\"aw1\",\"aw3\",\"nw1\",\"nw3\")\n",
    "#dgp <- c(\"nw2\",\"aw1\",\"nw1\",\"nw3\")\n",
    "grid <- expand.grid(n = n, p = p, dgp = dgp, stringsAsFactors = FALSE)\n",
    "var_matrix <- matrix(NA, ncol = length(n)*length(p), nrow = mse.reps)\n",
    "\n",
    "out <- lapply(1:nrow(grid), function(i) {\n",
    "  n <- grid$n[i]\n",
    "  p <- grid$p[i]\n",
    "  dgp <- grid$dgp[i]\n",
    "  mse <- replicate(mse.reps, {\n",
    "    data      <- generate_data_het(n = n, p = p, dgp = dgp, sigma.tau = 1)\n",
    "    data.test <- generate_data_het(n = 1000, p = p, dgp = dgp, sigma.tau = 1)\n",
    "    cf        <- causal_forest(data$X, data$Y, data$W)\n",
    "    tau.hat   <- predict(cf, data.test$X)$predictions\n",
    "      \n",
    "    mean((tau.hat - data.test$tau)^2)\n",
    "  })\n",
    "\n",
    "  data.frame(dgp = dgp, p = p, n = n, C.GRF = mse * 10)\n",
    "})\n",
    "\n",
    "rmse_table <- do.call(rbind, out) # master results stored in rmse_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df924cfd",
   "metadata": {},
   "source": [
    "### Dishonest Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "mse.reps <- 100   # Number of repetitions: Set to 100\n",
    "n <- c(100, 200, 300)\n",
    "p <- c(10, 50, 100, 300)\n",
    "\n",
    "dgp <- c(\"nw2\",\"ai2\",\"aw1\",\"aw3\",\"nw1\",\"nw3\")\n",
    "#dgp <- c(\"nw2\",\"aw1\",\"nw1\",\"nw3\")\n",
    "grid <- expand.grid(n = n, p = p, dgp = dgp, stringsAsFactors = FALSE)\n",
    "var_matrix <- matrix(NA, ncol = length(n)*length(p), nrow = mse.reps)\n",
    "\n",
    "out <- lapply(1:nrow(grid), function(i) {\n",
    "  n <- grid$n[i]\n",
    "  p <- grid$p[i]\n",
    "  dgp <- grid$dgp[i]\n",
    "  mse <- replicate(mse.reps, {\n",
    "    data <- generate_data_het(n = n, p = p, dgp = dgp, sigma.tau = 1)\n",
    "    data.test <- generate_data_het(n = 1000, p = p, dgp = dgp, sigma.tau = 1)\n",
    "    cf <- causal_forest(data$X, data$Y, data$W, honesty = FALSE)\n",
    "    tau.hat <- predict(cf, data.test$X)$predictions\n",
    "      \n",
    "    mean((tau.hat - data.test$tau)^2)\n",
    "  })\n",
    "\n",
    "  data.frame(dgp = dgp, p = p, n = n, C.GRF = mse * 10)\n",
    "})\n",
    "\n",
    "rmse_table_2 <- do.call(rbind, out)# master results stored in rmse_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4671f21",
   "metadata": {},
   "source": [
    "#### Output Preparation and Diplay Box-plot replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec919b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt large data into separate dataframes\n",
    "box_dat <- matrix(rmse_table[,4],nrow=mse.reps,ncol=72)\n",
    "\n",
    "MSE1 <-  reshape2::melt(box_dat[,1:12])[,3]\n",
    "MSE2 <-  reshape2::melt(box_dat[,13:24])[,3]\n",
    "MSE3 <-  reshape2::melt(box_dat[,25:36])[,3]\n",
    "MSE4 <-  reshape2::melt(box_dat[,37:48])[,3]\n",
    "MSE5 <-  reshape2::melt(box_dat[,49:60])[,3]\n",
    "MSE6 <-  reshape2::melt(box_dat[,61:72])[,3]\n",
    "\n",
    "SampleSize=rep(rep(n, each=100),4)\n",
    "dimension=rep(c(\"P = 10\", \"P = 50\", \"P=100\", \"P=300\"),each=300)\n",
    "data1=data.frame(SampleSize, dimension,MSE1)\n",
    "data2=data.frame(SampleSize, dimension,MSE2)\n",
    "data3=data.frame(SampleSize, dimension,MSE3)\n",
    "data4=data.frame(SampleSize, dimension,MSE4)\n",
    "data5=data.frame(SampleSize, dimension,MSE5)\n",
    "data6=data.frame(SampleSize, dimension,MSE6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into individual vectors for calculation of MSE\n",
    "\n",
    "seq_1 <- seq(1, 1200, by = 100)\n",
    "mse_table_1 <- rep(NA,12)\n",
    "mse_table_2 <- rep(NA,12)\n",
    "mse_table_3 <- rep(NA,12)\n",
    "mse_table_4 <- rep(NA,12)\n",
    "mse_table_5 <- rep(NA,12)\n",
    "mse_table_6 <- rep(NA,12)\n",
    "\n",
    "for (i in 1:length(seq_1)) {\n",
    "    mse_table_1[i] <- mean(data1[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_2[i] <- mean(data2[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_3[i] <- mean(data3[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_4[i] <- mean(data4[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_5[i] <- mean(data5[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_6[i] <- mean(data6[seq_1[i]:(seq_1[i]+99),3])\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600be629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine MSE results into one table \n",
    "hte_results <- round(rbind(mse_table_1,mse_table_2,mse_table_3,mse_table_4,mse_table_5,mse_table_6),2)\n",
    "\n",
    "# and then print table in LateX for export purposes\n",
    "#print.xtable(xtable(head(hte_results)), file = \"./Data1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b26ae",
   "metadata": {},
   "source": [
    "#### Redo Previous Steps for Dishonest Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt large data into separate dataframes\n",
    "box_dat2 <- matrix(rmse_table_2[,4],nrow=mse.reps,ncol=72)\n",
    "\n",
    "MSE1_2 <- reshape2::melt(box_dat2[,1:12])[,3]\n",
    "MSE2_2 <- reshape2::melt(box_dat2[,13:24])[,3]\n",
    "MSE3_2 <- reshape2::melt(box_dat2[,25:36])[,3]\n",
    "MSE4_2 <- reshape2::melt(box_dat2[,37:48])[,3]\n",
    "MSE5_2 <- reshape2::melt(box_dat2[,49:60])[,3]\n",
    "MSE6_2 <- reshape2::melt(box_dat2[,61:72])[,3]\n",
    "\n",
    "SampleSize=rep(rep(n, each=100),4)\n",
    "dimension=rep(c(\"P = 10\", \"P = 50\", \"P=100\", \"P=300\"),each=300)\n",
    "\n",
    "data1_2 = data.frame(SampleSize, dimension,MSE1_2)\n",
    "data2_2 = data.frame(SampleSize, dimension,MSE2_2)\n",
    "data3_2 = data.frame(SampleSize, dimension,MSE3_2)\n",
    "data4_2 = data.frame(SampleSize, dimension,MSE4_2)\n",
    "data5_2 = data.frame(SampleSize, dimension,MSE5_2)\n",
    "data6_2 = data.frame(SampleSize, dimension,MSE6_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3921ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into individual vectors for calculation of MSE\n",
    "\n",
    "seq_1 <- seq(1, 1200, by = 100)\n",
    "mse_table_1_2 <- rep(NA,12)\n",
    "mse_table_2_2 <- rep(NA,12)\n",
    "mse_table_3_2 <- rep(NA,12)\n",
    "mse_table_4_2 <- rep(NA,12)\n",
    "mse_table_5_2 <- rep(NA,12)\n",
    "mse_table_6_2 <- rep(NA,12)\n",
    "\n",
    "for (i in 1:length(seq_1)) {\n",
    "    mse_table_1_2[i] <- mean(data1_2[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_2_2[i] <- mean(data2_2[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_3_2[i] <- mean(data3_2[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_4_2[i] <- mean(data4_2[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_5_2[i] <- mean(data5_2[seq_1[i]:(seq_1[i]+99),3])\n",
    "    mse_table_6_2[i] <- mean(data6_2[seq_1[i]:(seq_1[i]+99),3])\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb71bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine MSE results into one table \n",
    "hte_results_2 <- round(rbind(mse_table_1_2,mse_table_2_2,mse_table_3_2,mse_table_4_2,mse_table_5_2,mse_table_6_2),2)\n",
    "\n",
    "# and then print table in LateX for export purposes\n",
    "#print.xtable(xtable(head(hte_results_2)), file = \"./Data2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e246a27",
   "metadata": {},
   "source": [
    "#### Graph the results for figure in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edea20e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colnames(data1_2) <- colnames(data1)\n",
    "colnames(data2_2) <- colnames(data2)\n",
    "colnames(data3_2) <- colnames(data3)\n",
    "colnames(data4_2) <- colnames(data4)\n",
    "colnames(data5_2) <- colnames(data5)\n",
    "colnames(data6_2) <- colnames(data6)\n",
    "\n",
    "Forest=rep(c(\"Honest\",\"Dishonest\"),each=1200)\n",
    "\n",
    "dataplus1 <- rbind(data1, data1_2)\n",
    "dataplus1 <- cbind(dataplus1,Forest)\n",
    "\n",
    "dataplus2 <- rbind(data2, data2_2)\n",
    "dataplus2 <- cbind(dataplus2,Forest)\n",
    "\n",
    "dataplus3 <- rbind(data3, data3_2)\n",
    "dataplus3 <- cbind(dataplus3,Forest)\n",
    "\n",
    "dataplus4 <- rbind(data4, data4_2)\n",
    "dataplus4 <- cbind(dataplus4,Forest)\n",
    "\n",
    "dataplus5 <- rbind(data5, data5_2)\n",
    "dataplus5 <- cbind(dataplus5,Forest)\n",
    "\n",
    "dataplus6 <- rbind(data6, data6_2)\n",
    "dataplus6 <- cbind(dataplus6,Forest)\n",
    "\n",
    "ggplot(dataplus1, aes(x=cut_width(SampleSize, width = 0.1), y=MSE1, fill=Forest)) + \n",
    "    geom_boxplot(color=\"black\",outlier.color=\"black\") + facet_grid(. ~ dimension) +\n",
    " scale_fill_brewer() +theme_light() +\n",
    " scale_x_discrete(labels= n) +\n",
    "theme(legend.position=\"none\", plot.title = element_text(size = 20), axis.text=element_text(size=16)) +\n",
    "# ggtitle(\"Unconfounded (RCT)\") +\n",
    "  xlab(\"Number of Observations\") + ylab(\"MSE\")\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "\n",
    "ggplot(dataplus2, aes(x=cut_width(SampleSize, width = 0.1), y=MSE2, fill=Forest)) + \n",
    "    geom_boxplot(color=\"black\",outlier.color=\"black\") + facet_grid(. ~ dimension) +\n",
    " scale_fill_brewer() +theme_light() +\n",
    " scale_x_discrete(labels= n) +\n",
    "theme(plot.title = element_text(size = 20), axis.text=element_text(size=16)) +\n",
    " #ggtitle(\"Unconfounded (RCT) with noisy covariates\") +\n",
    "  xlab(\"Number of Observations\") + ylab(\"MSE\")\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "\n",
    "ggplot(dataplus3, aes(x=cut_width(SampleSize, width = 0.1), y=MSE3, fill=Forest)) + \n",
    "    geom_boxplot(color=\"black\",outlier.color=\"black\") + facet_grid(. ~ dimension) +\n",
    " scale_fill_brewer() +theme_light() +\n",
    " scale_x_discrete(labels= n) +\n",
    "theme(legend.position=\"none\", plot.title = element_text(size = 20), axis.text=element_text(size=16)) +\n",
    " #ggtitle(\"Confounded Treatment with zero treatment effect\") +\n",
    "  xlab(\"Number of Observations\") + ylab(\"MSE\")\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "\n",
    "ggplot(dataplus4, aes(x=cut_width(SampleSize, width = 0.1), y=MSE4, fill=Forest)) + \n",
    "    geom_boxplot(color=\"black\",outlier.color=\"black\") + facet_grid(. ~ dimension) +\n",
    " scale_fill_brewer() +theme_light() +\n",
    " scale_x_discrete(labels= n) +\n",
    "theme(legend.position=\"none\", plot.title = element_text(size = 20), axis.text=element_text(size=16)) +\n",
    "# ggtitle(\"Confounded Treatment with Heterogeneous Treatments\") +\n",
    "  xlab(\"Number of Observations\") + ylab(\"MSE\")\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "\n",
    "ggplot(dataplus5, aes(x=cut_width(SampleSize, width = 0.1), y=MSE5, fill=Forest)) + \n",
    "    geom_boxplot(color=\"black\",outlier.color=\"black\") + facet_grid(. ~ dimension) +\n",
    " scale_fill_brewer() +theme_light() +\n",
    " scale_x_discrete(labels= n) +\n",
    "theme(legend.position=\"none\", plot.title = element_text(size = 20), axis.text=element_text(size=16)) +\n",
    " #ggtitle(\"Difficult nuisance parameters, linear treatment effect function\") +\n",
    "  xlab(\"Number of Observations\") + ylab(\"MSE\")\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "\n",
    "ggplot(dataplus6, aes(x=cut_width(SampleSize, width = 0.1), y=MSE6, fill=Forest)) + \n",
    "    geom_boxplot(color=\"black\",outlier.color=\"black\") + facet_grid(. ~ dimension) +\n",
    " scale_fill_brewer() +theme_light() +\n",
    " scale_x_discrete(labels= n) +\n",
    "theme(legend.position=\"none\", plot.title = element_text(size = 20), axis.text=element_text(size=16)) +\n",
    "# ggtitle(\"Difficult nuisance parameters, non-linear treatment effect function\") +\n",
    "  xlab(\"Number of Observations\") + ylab(\"MSE\")\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25af64",
   "metadata": {},
   "source": [
    "----\n",
    "## Part II - Empirical Applications\n",
    "---\n",
    "\n",
    "### (1) *The Impacts of Microcredit: Evidence from Bosnia and Herzegovina* (Cr√©pon et al., 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1301c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cleaned dataset from STATA and restrict to those who took part in endline interviews\n",
    "dataset_full <- as.data.frame(read_dta('Covariates-Bosnia-Baseline.dta'))\n",
    "dataset      <- dataset_full[dataset_full$followup == 1,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36feb9",
   "metadata": {},
   "source": [
    "#### Estimating Average Treatment Effect on the Treated for Self-Employment Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b95d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select outcome variables of interest\n",
    "dep_vars <- c(\"bm_revenue\",\"bm_expenses\",\"bm_profit\",\"inventory\",\"y_selfempl\",\n",
    "              \"bm_own\",\"bm_service\",\"bm_agric\")\n",
    "\n",
    "ate_mat <- matrix(NA, nrow = length(dep_vars), ncol = 8)\n",
    "\n",
    "# Loop over each outcome variable \n",
    "for (i in 1:length(dep_vars)) {\n",
    "    \n",
    "    # Remove obs with missing outcome variable\n",
    "    dataset <- dataset[!is.na(dataset[[dep_vars[i]]]),]\n",
    "    \n",
    "    # Covariates space, outcome Y, and treatment W\n",
    "    Y <- as.matrix(dataset[,c(dep_vars[i]),drop=FALSE])  # outcome variable \n",
    "    W <- as.matrix(dataset[,c(\"treatment\")])\n",
    "    X <- as.matrix(dataset[,c(\"b_resp_female\",\"b_resp_age\",\"b_resp_age2\",\"b_resp_ms1\",\n",
    "                              \"b_resp_ms4\",\"b_resp_ms5\",\"b_resp_ss\",\"b_resp_ul\",\n",
    "                              \"b_kids_05\",\"b_kids_610\",\"b_kids_1116\",\"b_hhmem_female\", \n",
    "                              \"b_hhmem_employed\",\"b_hhmem_school\",\"b_hhmem_retired\")])\n",
    "    \n",
    "    df1 = data.frame(X)\n",
    "    res <- cbind(df1, do.call(cbind,combn(colnames(df1), 2, \n",
    "               FUN= function(x) list(df1[x[1]]*df1[x[2]]))))\n",
    "    colnames(res)[-(seq_len(ncol(df1)))] <-  combn(colnames(df1), 2, \n",
    "                 FUN = paste, collapse=\"_\")\n",
    "      \n",
    "    X <- as.matrix(res)                                   \n",
    "    data <- list('X' = X, 'Y' = Y, 'W' = W)\n",
    "\n",
    "    # DML requires specific data format\n",
    "    dml_data <- double_ml_data_from_data_frame(na.omit(data.table(cbind(X,W,Y))),              \n",
    "                                               y_col = dep_vars[i], d_cols = \"V121\")  \n",
    "    \n",
    "    set.seed(123)      # replicability\n",
    "    \n",
    "    cf_honest    <- causal_forest(data$X, data$Y, data$W, honesty = TRUE,tune.parameters = \"all\",seed = 123)    # train the GRF Causal Forest\n",
    "    \n",
    "    ## DML Random Forest\n",
    "    learner <- lrn(\"regr.ranger\", num.trees=200, min.node.size=2, max.depth=5)\n",
    "    g_hat <- learner$clone()                                  # use RF to estimate nuisance g() and m()\n",
    "    m_hat <- learner$clone()\n",
    "\n",
    "    DML_PLR  <- DoubleMLPLR$new(dml_data, g_hat, m_hat)   # initialize the DML Partially Linear Model \n",
    "    DML_PLR$fit()  \n",
    "    params_rf    <- cbind(DML_PLR$coef,DML_PLR$se)\n",
    "\n",
    "    ## DML LASSO\n",
    "    learner <- lrn(\"regr.cv_glmnet\", s=\"lambda.min\",standardize=TRUE)\n",
    "    g_hat <- learner$clone()                                  # use RF to estimate nuisance g() and m()\n",
    "    m_hat <- learner$clone()\n",
    "\n",
    "    DML_PLR  <- DoubleMLPLR$new(dml_data, g_hat, m_hat)   # initialize the DML Partially Linear Model \n",
    "    DML_PLR$fit()  \n",
    "    params_lasso    <- cbind(DML_PLR$coef,DML_PLR$se)\n",
    "\n",
    "    # Double Selection\n",
    "    DS_c  <- summary(rlassoEffect(x = data$X, y = data$Y, d=data$W, method = \"double selection\"))$coefficients[1,1]\n",
    "    DS_se <- summary(rlassoEffect(x = data$X, y = data$Y, d=data$W, method = \"double selection\"))$coefficients[1,2]\n",
    "    \n",
    "    ate_mat[i,1:2] <- average_treatment_effect(cf_honest)\n",
    "    ate_mat[i,3:4] <- params_lasso\n",
    "    ate_mat[i,5:6] <- params_rf\n",
    "    ate_mat[i,7:8] <- cbind(DS_c,DS_se)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49450c30",
   "metadata": {},
   "source": [
    "#### Print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS benchmark taken directly from paper.\n",
    "benchmark_ols <- matrix(c(1384, 601.4, 671.9, 0.0513, 0.0602, 0.0584, 0.0312, 0.0350,\n",
    "                          981.4, 592.9, 541.3, 0.020, 0.0293, 0.031,  0.025, 0.028),\n",
    "                          nrow = length(dep_vars), ncol = 2)\n",
    "\n",
    "# combine OLS and ML estimates\n",
    "results_mat <- cbind(benchmark_ols,ate_mat)\n",
    "\n",
    "\n",
    "out <- cbind(as.data.frame(c(rbind(results_mat[,1],results_mat[,2]))),\n",
    "      as.data.frame(c(rbind(results_mat[,3],results_mat[,4]))),\n",
    "      as.data.frame(c(rbind(results_mat[,5],results_mat[,6]))),\n",
    "      as.data.frame(c(rbind(results_mat[,7],results_mat[,8]))),\n",
    "      as.data.frame(c(rbind(results_mat[,9],results_mat[,10]))))\n",
    "\n",
    "# uncomment to save locally\n",
    "#print.xtable(xtable(out, digits = 4), file = \"./Data3.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0fe119",
   "metadata": {},
   "source": [
    "### (2) *Effect of 401(k) eligibility and participation on net financial assets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cleaned dataset from STATA \n",
    "dataset <- as.data.frame(read_dta('sipp1991.dta'))\n",
    "\n",
    "Y <- as.matrix(dataset[,c(\"net_tfa\"),drop=FALSE])  # outcome variable is net financial assets \n",
    "W <- as.matrix(dataset[,c(\"e401\"), drop=FALSE])    # binary indicator for 401(k) eligibility\n",
    "\n",
    "# Baseline variables\n",
    "X_1 <- as.matrix(dataset[,c(\"age\",\"inc\",\"educ\",\"fsize\",\"marr\",\"twoearn\",\"db\",\"pira\",\"hown\")])\n",
    "\n",
    "# Baseline + interactions\n",
    "df1 = data.frame(X_1)\n",
    "res <- cbind(df1, do.call(cbind,combn(colnames(df1), 2,\n",
    "             FUN= function(x) list(df1[x[1]]*df1[x[2]]))))\n",
    "             colnames(res)[-(seq_len(ncol(df1)))] <-  combn(colnames(df1), 2, \n",
    "                 FUN = paste, collapse=\"_\")\n",
    "            \n",
    "X_2 <- as.matrix(res)        \n",
    "\n",
    "# Baseline + interactions + quadratics\n",
    "X_3 <- as.data.frame(cbind(X_2,poly(dataset$age, 6, raw=TRUE),\n",
    "                poly(dataset$inc, 8, raw=TRUE),\n",
    "                poly(dataset$educ, 4, raw=TRUE),\n",
    "                poly(dataset$fsize, 2, raw=TRUE)))\n",
    "                                      \n",
    "colnames(X_3)[46:ncol(X_3)] <- c(\"age_1\",\"age_2\",\"age_2\",\"age_4\",\"age_5\",\"age_6\",\n",
    "                          \"inc_1\",\"inc_2\",\"inc_3\",\"inc_4\",\"inc_5\",\"inc_6\",\"inc_7\",\"inc_8\",\n",
    "                           \"educ_1\",\"educ_2\",\"educ_3\",\"educ_4\",\n",
    "                           \"fsize_1\",\"fsize_2\")\n",
    "\n",
    "X_3 <- X_3[,!names(X_3) %in% c(\"age_1\",\"inc_1\",\"educ_1\",\"fsize_1\")]\n",
    "                                      \n",
    "df_list <- list(\"X_1\" = X_1,\"X_2\" = X_2, \"X_3\" = X_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4cd80",
   "metadata": {},
   "source": [
    "#### Estimating Average Treatment Effect of 401(k) eligibility on Net Financial Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd184fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ate_mat <- matrix(NA, nrow = 3, ncol = 8)\n",
    "                                      \n",
    "for (i in 1:3) {\n",
    "    \n",
    "    X <- as.matrix(df_list[[i]])\n",
    "    data <- list('X' = X, 'Y' = Y, 'W' = W)\n",
    "    \n",
    "    # DML requires specific data format\n",
    "    dml_data <- double_ml_data_from_data_frame(na.omit(data.table(cbind(X,W,Y))),              \n",
    "                                               y_col = \"net_tfa\", d_cols = \"e401\")  \n",
    "    \n",
    "    set.seed(123)      # replicability\n",
    "    \n",
    "    cf_honest    <- causal_forest(data$X, data$Y, data$W, honesty = TRUE,tune.parameters = \"all\",seed = 123)    # train the GRF Causal Forest\n",
    "    \n",
    "    ## DML Random Forest\n",
    "    learner <- lrn(\"regr.ranger\", num.trees=200, min.node.size=2, max.depth=5)\n",
    "    g_hat <- learner$clone()                                  # use RF to estimate nuisance g() and m()\n",
    "    m_hat <- learner$clone()\n",
    "\n",
    "    DML_PLR  <- DoubleMLPLR$new(dml_data, g_hat, m_hat)   # initialize the DML Partially Linear Model \n",
    "    DML_PLR$fit()  \n",
    "    params_rf    <- cbind(DML_PLR$coef,DML_PLR$se)\n",
    "\n",
    "    ## DML LASSO\n",
    "    learner <- lrn(\"regr.cv_glmnet\", s=\"lambda.min\",standardize=TRUE)\n",
    "    g_hat <- learner$clone()                                  # use RF to estimate nuisance g() and m()\n",
    "    m_hat <- learner$clone()\n",
    "\n",
    "    DML_PLR  <- DoubleMLPLR$new(dml_data, g_hat, m_hat)   # initialize the DML Partially Linear Model \n",
    "    DML_PLR$fit()  \n",
    "    params_lasso    <- cbind(DML_PLR$coef,DML_PLR$se)\n",
    "\n",
    "    # Double Selection\n",
    "    DS_c  <- summary(rlassoEffect(x = data$X, y = data$Y, d=data$W, method = \"double selection\"))$coefficients[1,1]\n",
    "    DS_se <- summary(rlassoEffect(x = data$X, y = data$Y, d=data$W, method = \"double selection\"))$coefficients[1,2]\n",
    "    \n",
    "    ate_mat[i,1:2] <- average_treatment_effect(cf_honest, target.sample = \"all\",  method = \"TMLE\")\n",
    "    ate_mat[i,3:4] <- params_lasso\n",
    "    ate_mat[i,5:6] <- params_rf\n",
    "    ate_mat[i,7:8] <- cbind(DS_c,DS_se)\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05200836",
   "metadata": {},
   "source": [
    "#### Print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out <- cbind(as.data.frame(c(rbind(ate_mat[,1],ate_mat[,2]))),\n",
    "             as.data.frame(c(rbind(ate_mat[,3],ate_mat[,4]))),\n",
    "             as.data.frame(c(rbind(ate_mat[,5],ate_mat[,6]))),\n",
    "             as.data.frame(c(rbind(ate_mat[,7],ate_mat[,8]))))\n",
    "\n",
    "# uncomment to save locally\n",
    "#print.xtable(xtable(out, digits = 0), file = \"./Data4.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cedeab",
   "metadata": {},
   "source": [
    "#### Treatment Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5025e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y <- as.matrix(dataset[,c(\"net_tfa\"),drop=FALSE])  # outcome variable is net financial assets \n",
    "W <- as.matrix(dataset[,c(\"e401\"), drop=FALSE])                # binary indicator \n",
    "X <- as.matrix(dataset[,c(\"age\",\"inc\",\"educ\",\"fsize\",\"marr\",\"twoearn\",\"db\",\"pira\",\"hown\")])\n",
    "data <- list('X' = X, 'Y' = Y, 'W' = W)\n",
    "\n",
    "cf_honest <- causal_forest(data$X, data$Y, data$W, honesty = TRUE,tune.parameters = \"all\", seed = 123)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce833d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the CATEs\n",
    "preds <- predict(cf_honest, estimate.variance = TRUE)\n",
    "tau.hat <- preds$predictions\n",
    "pardef = par(mar = c(5, 4, 4, 2) + 0.5, cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)\n",
    "hist(tau.hat, xlab = \"estimated CATE\", main = \"\")\n",
    "\n",
    "# Plotting propensity score\n",
    "DF = as.data.frame(cbind(X,W,tau.hat))\n",
    "DF$W.hat = cf_honest$W.hat\n",
    "#DF = subset(DF, DF$e401 == 0)\n",
    "\n",
    "pardef = par(mar = c(5, 4, 4, 2) + 0.5, cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)\n",
    "boxplot(DF$W.hat ~ DF$educ, data = DF, ylab = \"Propensity Score\", xlab = \"Years of Education\")\n",
    "lines(smooth.spline(DF$educ, DF$W.hat), lwd = 2, col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma.hat <- sqrt(preds$variance.estimates)\n",
    "CI_95 = tau.hat + 1.96 * sigma.hat\n",
    "CI_5 =  tau.hat - 1.96 * sigma.hat\n",
    "  \n",
    "cf_CI <- as.data.frame(cbind(tau.hat,CI_95,CI_5))\n",
    "colnames(cf_CI) <- c(\"pred\",\"CI_95\",\"CI_5\")\n",
    "\n",
    "cf_melt <- reshape2::melt(cf_CI[order(cf_CI$pred),])\n",
    "cf_melt$ID <- rep(1:nrow(cf_CI),times=3)\n",
    "\n",
    "cols <- c(\"#000000\", \"#00BA38\", \"#0072B2\")\n",
    "\n",
    "\n",
    "# Plot the CATE estimates + CI for 5% and 95%\n",
    "options(repr.plot.width=9, repr.plot.height=6)\n",
    "ggplot(cf_melt, aes(x=ID,y=value,group=variable))+\n",
    "  theme_minimal()  +ylim(0,20000) +\n",
    "  geom_line(aes(color=variable,alpha=variable),size=1.1)+\n",
    "  scale_alpha_manual(values=c(1.0,0.01,0.05)) +\n",
    "  labs(y = \"Estimated Treatment Effect \", x = \"Observation\") +\n",
    "  theme(legend.position=\"none\",legend.justification = 'center',plot.title = element_text(color=\"black\", face=\"bold\", size=15), axis.text=element_text(size=12))+ \n",
    "  scale_color_manual(values = cols) +\n",
    "  geom_smooth(data=cf_melt[cf_melt[\"variable\"] == \"CI_5\" | cf_melt[\"variable\"] == \"CI_95\",],linetype=\"dashed\", size=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
